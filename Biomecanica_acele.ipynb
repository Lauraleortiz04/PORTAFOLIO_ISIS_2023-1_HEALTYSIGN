{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vpython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdqJ3STCery0",
        "outputId": "e56527b5-ffae-465b-96e5-a83aa5399359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vpython\n",
            "  Downloading vpython-7.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_24_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter (from vpython)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting jupyter-server-proxy (from vpython)\n",
            "  Downloading jupyter_server_proxy-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vpython) (1.22.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from vpython) (5.5.6)\n",
            "Collecting autobahn<27,>=22.6.1 (from vpython)\n",
            "  Downloading autobahn-23.1.2.tar.gz (480 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.7/480.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting txaio>=21.2.1 (from autobahn<27,>=22.6.1->vpython)\n",
            "  Downloading txaio-23.1.1-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from autobahn<27,>=22.6.1->vpython) (40.0.2)\n",
            "Collecting hyperlink>=21.0.0 (from autobahn<27,>=22.6.1->vpython)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autobahn<27,>=22.6.1->vpython) (67.7.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->vpython) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->vpython) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->vpython) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->vpython) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->vpython) (6.3.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->vpython) (6.4.8)\n",
            "Collecting qtconsole (from jupyter->vpython)\n",
            "  Downloading qtconsole-5.4.3-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->vpython) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->vpython) (6.5.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->vpython) (7.7.1)\n",
            "Collecting aiohttp (from jupyter-server-proxy->vpython)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-server>=1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->vpython) (1.24.0)\n",
            "Collecting simpervisor>=0.4 (from jupyter-server-proxy->vpython)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->autobahn<27,>=22.6.1->vpython) (1.15.1)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.10/dist-packages (from hyperlink>=21.0.0->autobahn<27,>=22.6.1->vpython) (3.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->vpython)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->vpython) (4.8.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (3.6.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (21.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (5.3.0)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (5.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (23.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (0.16.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (0.17.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.0->jupyter-server-proxy->vpython) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->vpython) (2.8.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (2.1.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (0.7.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->vpython) (1.2.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->jupyter-server-proxy->vpython) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->jupyter-server-proxy->vpython) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->jupyter-server-proxy->vpython)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->jupyter-server-proxy->vpython)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->jupyter-server-proxy->vpython)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->jupyter-server-proxy->vpython)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->jupyter-server-proxy->vpython)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->vpython) (3.6.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->vpython) (3.0.7)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->vpython) (1.5.6)\n",
            "Collecting qtpy>=2.0.1 (from qtconsole->jupyter->vpython)\n",
            "  Downloading QtPy-2.3.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.0->jupyter-server-proxy->vpython) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->autobahn<27,>=22.6.1->vpython) (2.21)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->vpython) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.0->jupyter-server-proxy->vpython) (3.3.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.0->jupyter-server-proxy->vpython) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.0->jupyter-server-proxy->vpython) (4.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->vpython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->vpython) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel->vpython) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.0->jupyter-server-proxy->vpython) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->vpython) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->vpython) (0.5.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.0->jupyter-server-proxy->vpython) (0.19.3)\n",
            "Building wheels for collected packages: autobahn\n",
            "  Building wheel for autobahn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autobahn: filename=autobahn-23.1.2-cp310-cp310-linux_x86_64.whl size=706999 sha256=ef44236eba8645764340d0cdcd97ada7d9c9233af8890bcb41ba017d9b2a99ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/a4/60/d547cb0414567a087281bd1474426e29194bf88b1972dba289\n",
            "Successfully built autobahn\n",
            "Installing collected packages: txaio, simpervisor, qtpy, multidict, jedi, hyperlink, frozenlist, async-timeout, yarl, aiosignal, autobahn, aiohttp, qtconsole, jupyter-server-proxy, jupyter, vpython\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 autobahn-23.1.2 frozenlist-1.3.3 hyperlink-21.0.0 jedi-0.18.2 jupyter-1.0.0 jupyter-server-proxy-4.0.0 multidict-6.0.4 qtconsole-5.4.3 qtpy-2.3.1 simpervisor-1.0.0 txaio-23.1.1 vpython-7.6.4 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Bvh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7NQTucxQV4",
        "outputId": "7c1b717f-1830-472d-df47-26885858c6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Bvh\n",
            "  Downloading bvh-0.3.tar.gz (1.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Bvh\n",
            "  Building wheel for Bvh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Bvh: filename=bvh-0.3-py3-none-any.whl size=2500 sha256=bf7f00eaad315d9881cb58c533a67b27003e51961957cae765dbc1ad4487c53f\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/52/82/8265e7618cbd27122b8f43a8b895bb61b377e236a0e656dd8b\n",
            "Successfully built Bvh\n",
            "Installing collected packages: Bvh\n",
            "Successfully installed Bvh-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bvh import Bvh\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import glob\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "9c55Cue5lWRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHFnE9GUkHaY",
        "outputId": "6ca98921-1578-43a4-afc9-15b2a0fad11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tennis-MoCap'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 124 (delta 7), reused 115 (delta 3), pack-reused 4\u001b[K\n",
            "Receiving objects: 100% (124/124), 75.89 MiB | 19.36 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "Updating files: 100% (103/103), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jdpulgarin/Tennis-MoCap/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROYECCION PCA PARA CADA UNO DE LOS CANALES,LUEGO SE CONCATENA EN UNA SOLA FILA , SE ORGANIZA UNA MATRIZ DONDE SE ENLACE LOS VECTORES CON LAS ETIQUETAS, LUEGO SE HACE MATRIZ DE DISTANCIA"
      ],
      "metadata": {
        "id": "30xm5uK_9ZZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "carpe='/content/Tennis-MoCap/data'\n",
        "filel= glob.glob(os.path.join(carpe, \"*\"))"
      ],
      "metadata": {
        "id": "Uvo222yAqPdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"]=(10,5)"
      ],
      "metadata": {
        "id": "3C0-2Dp34QBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pasar de rotacion a posicion, se debe de hacer estimaciones estadisticaas con las series de tiempo"
      ],
      "metadata": {
        "id": "AErNy-Q23poP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paciente 1"
      ],
      "metadata": {
        "id": "m_qvaGetbx5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paciente 1 mov 1"
      ],
      "metadata": {
        "id": "sOF9tov58Lph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=0\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca1=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca1.append(X_pca)"
      ],
      "metadata": {
        "id": "wb3u1PTYp4Gm",
        "outputId": "8b018ce5-d424-4464-8bd2-391c8b0168bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7b97728cd33d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#==========andquirir nombres=============\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmocap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpaciente\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_joints_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mocap' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "primero se hace el PCA para todos los datos y luego se le hace reshape "
      ],
      "metadata": {
        "id": "MfcVkp3K25KA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paciente 1 mov 2"
      ],
      "metadata": {
        "id": "8fctc1WZ80Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca2=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca2.append(X_pca)"
      ],
      "metadata": {
        "id": "SBgMrvk384ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paciente 1 mov 3"
      ],
      "metadata": {
        "id": "Q877QOe4TJiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca3=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca3.append(X_pca)"
      ],
      "metadata": {
        "id": "XYMo-6d2TSnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##paciente 1 mov 4"
      ],
      "metadata": {
        "id": "Fw0kwH8XTe34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca4=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca4.append(X_pca)"
      ],
      "metadata": {
        "id": "uvEPBoW0TopA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##paciente1 mov 5\n"
      ],
      "metadata": {
        "id": "d76fpj3EVnNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca5=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca5.append(X_pca)"
      ],
      "metadata": {
        "id": "qrk_BE9UWQRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##paciente 1 mov 6\n"
      ],
      "metadata": {
        "id": "ducScSvAWQzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "mocap=[]\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca6=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca6.append(X_pca)"
      ],
      "metadata": {
        "id": "W6XX7E6EWnhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##paciente 1 mov 7"
      ],
      "metadata": {
        "id": "cLaysoaCWouU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca7=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca7.append(X_pca)"
      ],
      "metadata": {
        "id": "O-KltKtsXJh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2X8f40aRXLz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paciente 2"
      ],
      "metadata": {
        "id": "afTOxLoIb6h7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##paciente 2 mov 1"
      ],
      "metadata": {
        "id": "aQUV3I2Eb-Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca2_1=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca2_1.append(X_pca)"
      ],
      "metadata": {
        "id": "hUBhM2qfcvmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paciente 2 mov 2"
      ],
      "metadata": {
        "id": "2s7SpcRlc4dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca2_2=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca2_2.append(X_pca)"
      ],
      "metadata": {
        "id": "L6cQiA-nc8sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paciente 2 mov 3"
      ],
      "metadata": {
        "id": "QYfQKW0gdKRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca2_3=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca2_3.append(X_pca)"
      ],
      "metadata": {
        "id": "IZ_7-X-NdOHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paciente 2 mov 4"
      ],
      "metadata": {
        "id": "_K6qsr0bdYSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paciente=paciente+1\n",
        "\n",
        "#==========andquirir nombres=============\n",
        "f=mocap[paciente].get_joints_names()\n",
        "nom=[]\n",
        "for g in f:\n",
        "  nom.append(g)\n",
        "  \n",
        "r,t,u,w,g,h=(mocap[paciente].joint_channels(nom[0]))\n",
        " \n",
        "pala=[r,t,u,w,g,h]\n",
        "\n",
        "for g in nom:\n",
        "  \n",
        "  if g!=nom[0]:\n",
        "    z,y,x=(mocap[paciente].joint_channels(g))\n",
        "    pala.extend([z+g,y+g,x+g])\n",
        "#========================================crear dataframe==================\n",
        "# Obtener datos de la animación\n",
        "frames = mocap[paciente].frames\n",
        "#frame_time = mocap[1].frame_time\n",
        "\n",
        "# Convertir datos a un DataFrame de pandas\n",
        "df = pd.DataFrame(frames, columns=pala)\n",
        "#df.insert(0, \"Time\", [i*frame_time for i in range(len(frames))])\n",
        "#=========================================pasar de str a float======================\n",
        "for col in df.columns:\n",
        "  df[col]=df[col].astype(float)\n",
        "# Guardar DataFrame como archivo CSV\n",
        "\n",
        "#===========================normalizar con respecto a cadera=====================\n",
        "cols_x = df.columns[df.columns.str.contains('X')]\n",
        "df[cols_x]=df[cols_x].sub(df['Xrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "cols_z = df.columns[df.columns.str.contains('Z')]\n",
        "df[cols_z]=df[cols_z].sub(df['Zrotation'], axis=0)\n",
        "\n",
        "df1=df.loc[:,'ZrotationChest':]\n",
        "\n",
        "#===============================PCA===========================================\n",
        "a,b=0,3\n",
        "x_pca2_4=[]\n",
        "while b < len(df1.columns):\n",
        "# Create principal components\n",
        "  pca = PCA(n_components=1)\n",
        "  pca.fit(df1.iloc[:,a:b])\n",
        "  X_pca= pca.transform(df1.iloc[:,a:b])\n",
        "  # Convert to dataframe\n",
        "  #component_names = [f\"PC{i+1}\" for i in range(X_pca1.shape[1])]\n",
        "  X_pca = pd.DataFrame(X_pca, \n",
        "                        #columns=component_names\n",
        "                        )\n",
        "  a+=3\n",
        "  b+=3\n",
        "  x_pca2_1.append(X_pca)"
      ],
      "metadata": {
        "id": "duWB0mzGjHKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}